{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping an html page (loading and searching it's contents)\n",
    "\n",
    "# Local:  saved in a file on your computer\n",
    "# Remote: somewhere on the web\n",
    "\n",
    "To fully understand this notebook, open the example_html.html file in another tab, and open it's example_html.html's source code in a third tab (or even better: in browser's View>Developer tools). You will see in a minute what is the exact addres of that file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scraping, we need a few of different libraries, most notably Beautifulsoup. Let's first import these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply enter a web page as a string and open it. Afterwards, BeautifulSoup converts it into a BeautifulSoup object which has many interesting functions and attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste this url to your browser to see the demo website (copy the whole thing, together wioth the file:// part):\n",
      "file:///C:\\Users\\reena\\OneDrive\\Documents\\GitHub\\web-and-social-network-analytics-notes\\week1-web-scraping-and-analytics/example_html.html\n"
     ]
    }
   ],
   "source": [
    "# website address\n",
    "#page = 'http://www.uebs.ed.ac.uk'\n",
    "\n",
    "# open the url and store the website\n",
    "#website = urlopen(page)\n",
    "\n",
    "# for now we use a local file (os.getcwd() gets the Current Working Directory, aka. the folder you're in)\n",
    "file_url = \"file:///\"+os.getcwd()+\"/example_html.html\"\n",
    "website_source_code = urlopen(file_url)\n",
    "\n",
    "\n",
    "# in another tab: (open the example_html.html file directly in your browser to see how it will look like)\n",
    "# then in your browser, right click and select 'view source', or open developer tools to see the source\n",
    "print(\"Paste this url to your browser to see the demo website (copy the whole thing, together wioth the file:// part):\")\n",
    "print( file_url)\n",
    "\n",
    "# convert the website's content, for this a parser is needed. In this case a html parser\n",
    "soup = BeautifulSoup(website_source_code, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "\n",
      "<html>\n",
      "<head>\n",
      "<style>\r\n",
      ".hipster {\r\n",
      "\tbackground-color:black;\r\n",
      "\tcolor:red;\r\n",
      "\tpadding:22px;\r\n",
      "}\r\n",
      "</style>\n",
      "<script type=\"text/javascript\">\r\n",
      "  var numberOfClicks = 0;\r\n",
      "  function clickedButton()\r\n",
      "  {\r\n",
      "      numberOfClicks += 1;\r\n",
      "    document.getElementById(\"clickableButton\").text=\"GOOD JOB! You clicked me \"+numberOfClicks+\" times. If you reload the page I will go back to the original state :)\"; \r\n",
      "  }\r\n",
      "</script>\n",
      "</head>\n",
      "<body>\n",
      "<h1 title=\"A header\">Example for Media and Web Analytics</h1>\n",
      "<p>Here you typically see some text.\r\n",
      "Ocassionaly, an URL is present <a href=\"http://www.ed.ac.uk\">UoE</a>\n",
      "</p>\n",
      "<h1 title=\"A header\">Some other stuff</h1>\n",
      "<h2>3 Rows and 3 Columns:</h2>\n",
      "<table>\n",
      "<tr>\n",
      "<td>100</td>\n",
      "<td>200</td>\n",
      "<td>300</td>\n",
      "</tr>\n",
      "<tr id=\"middle_row\">\n",
      "<td>400</td>\n",
      "<td>500</td>\n",
      "<td>600</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>700</td>\n",
      "<td>800</td>\n",
      "<td>900</td>\n",
      "</tr>\n",
      "</table>\n",
      "<a href=\"#\" id=\"clickableButton\" onclick=\"clickedButton()\" target=\"none\">CLICK ME!</a>\n",
      "<div class=\"hipster\">\n",
      "<h2>A Dangerous-Looking Header</h2>\n",
      "<p>\r\n",
      "I look like a paragraph Kylo Ren could have written.\r\n",
      "</p>\n",
      "</div>\n",
      "<div class=\"hipster\">\n",
      "<h2>Another Dangerous-Looking Header</h2>\n",
      "<p>\r\n",
      "This one is not as scary.\r\n",
      "</p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# here's a complete html of the page, but it's easier to read if you open it's source using the url above\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete tag code:  <h1 title=\"A header\">Example for Media and Web Analytics</h1>\n",
      "Just the text in the tag:  Example for Media and Web Analytics\n",
      "\n",
      "Complete tag code:  <h1 title=\"A header\">Some other stuff</h1>\n",
      "Just the text in the tag:  Some other stuff\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# .find_all retrieves all tags containing 'h1':\n",
    "h1Tags = soup.find_all('h1')\n",
    "for h1 in h1Tags:\n",
    "    print('Complete tag code: ', h1)\n",
    "    print(\"Just the text in the tag: \", h1.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td tags: 100\n",
      "td tags: 200\n",
      "td tags: 300\n",
      "td tags: 400\n",
      "td tags: 500\n",
      "td tags: 600\n",
      "td tags: 700\n",
      "td tags: 800\n",
      "td tags: 900\n"
     ]
    }
   ],
   "source": [
    "# Added this one for practice. \n",
    "tdTags = soup.find_all('td')\n",
    "for td in tdTags:\n",
    "    print('td tags:', td.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleTags = soup.find_all('title')\n",
    "for title in titleTags:\n",
    "    print('Complete tag code: ', title)\n",
    "    print(\"Just the text in the tag: \", title.text)\n",
    "    \n",
    "# nothing will be printed. there are no tags <title> </title> there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the html is all about finding components you need:\n",
    "\n",
    "### .find_all( ) will find all things that match criteria, in a list\n",
    "### .find( ) will find just the first item that mathes the criteria\n",
    "\n",
    "You can use it on the whole website, like `a_table = soup.find(\"table\")` or on an element you found before `rows = a_table.find(\"tr\")`\n",
    "\n",
    "You can seek for types of tags, classes or ids  `soup.find(\"h1\")`,  `soup.find(id=\"main_navigation\")`, `soup.find(class=\"warning_message\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it is very frequent to fetch an element by its unique id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete tag code:  <tr id=\"middle_row\">\n",
      "<td>400</td>\n",
      "<td>500</td>\n",
      "<td>600</td>\n",
      "</tr>\n",
      "Just the text in the tag:  \n",
      "400\n",
      "500\n",
      "600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "middle_row = soup.find(id='middle_row')\n",
    "\n",
    "print('Complete tag code: ', middle_row)\n",
    "print(\"Just the text in the tag: \", middle_row.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comeplete tag: <a href=\"#\" id=\"clickableButton\" onclick=\"clickedButton()\" target=\"none\">CLICK ME!</a>\n",
      "\n",
      "Just the text: CLICK ME!\n"
     ]
    }
   ],
   "source": [
    "#Added for practice\n",
    "click_button = soup.find(id='clickableButton')\n",
    "\n",
    "print('Comeplete tag:', click_button)\n",
    "print('\\nJust the text:', click_button.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find children:\n",
    "\n",
    "When, like above, a tag contains some children (tags inside it) you can extract them into a list.\n",
    "The example would be above table row `<tr></tr>` includes three table data `<td></td>`\n",
    "    \n",
    "```.findChildren()```will give you a list with all tags inside of a given tag\n",
    "\n",
    "You can specify exactly which children, if you want, like with the `.find()`. So you could use `.findChildren(\"tr\")` or `.findChildren(class=\"warning_message\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete tag code:  <td>400</td> Just the text in the tag:  400\n",
      "Complete tag code:  <td>500</td> Just the text in the tag:  500\n",
      "Complete tag code:  <td>600</td> Just the text in the tag:  600\n"
     ]
    }
   ],
   "source": [
    "middle_row = soup.find(id='middle_row')\n",
    "cells_in_the_row = middle_row.findChildren()\n",
    "for cell in cells_in_the_row:\n",
    "    print('Complete tag code: ', cell, \"Just the text in the tag: \", cell.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <td>400</td>\n",
      "1 <td>500</td>\n",
      "2 <td>600</td>\n"
     ]
    }
   ],
   "source": [
    "#Added for pratice\n",
    "middle_row_ex= soup.find(id='middle_row')\n",
    "cells_children= middle_row_ex.findChildren()\n",
    "for count, each_cell in enumerate(cells_children):\n",
    "    print(count, each_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can dive deeper into certain tags, for example here you look for all divs from the (CSS) class called hipster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole tag:\n",
      " <div class=\"hipster\">\n",
      "<h2>A Dangerous-Looking Header</h2>\n",
      "<p>\r\n",
      "I look like a paragraph Kylo Ren could have written.\r\n",
      "</p>\n",
      "</div> \n",
      "\n",
      "Just the text:  \n",
      "A Dangerous-Looking Header\n",
      "\r\n",
      "I look like a paragraph Kylo Ren could have written.\r\n",
      "\n",
      "\n",
      "whole tag:\n",
      " <div class=\"hipster\">\n",
      "<h2>Another Dangerous-Looking Header</h2>\n",
      "<p>\r\n",
      "This one is not as scary.\r\n",
      "</p>\n",
      "</div> \n",
      "\n",
      "Just the text:  \n",
      "Another Dangerous-Looking Header\n",
      "\r\n",
      "This one is not as scary.\r\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_elements = soup.find_all(\"div\", {\"class\" : \"hipster\" })\n",
    "for element in class_elements:\n",
    "    print('whole tag:\\n', str(element), '\\n')\n",
    "    #print('Just the text: ', line.text)\n",
    "    print('Just the text: ', element.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background :yellow' > <font color='red'> Check this one</font>  </span>\n",
    " <font color='red'>Why does it print twice. Need to check</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole tag: [<h1 title=\"A header\">Example for Media and Web Analytics</h1>, <h1 title=\"A header\">Some other stuff</h1>]\n",
      "whole tag: [<h1 title=\"A header\">Example for Media and Web Analytics</h1>, <h1 title=\"A header\">Some other stuff</h1>]\n"
     ]
    }
   ],
   "source": [
    "#Added for practice. \n",
    "title_elements= soup.find_all(\"h1\", {\"title\": \"A header\"})\n",
    "for each_ele in title_elements:\n",
    "    print(\"whole tag:\", title_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the elements out of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 0\n",
      "whole html: <td>100</td> \tJust content: 100\n",
      "whole html: <td>200</td> \tJust content: 200\n",
      "whole html: <td>300</td> \tJust content: 300\n",
      "Row: 1\n",
      "whole html: <td>400</td> \tJust content: 400\n",
      "whole html: <td>500</td> \tJust content: 500\n",
      "whole html: <td>600</td> \tJust content: 600\n",
      "Row: 2\n",
      "whole html: <td>700</td> \tJust content: 700\n",
      "whole html: <td>800</td> \tJust content: 800\n",
      "whole html: <td>900</td> \tJust content: 900\n"
     ]
    }
   ],
   "source": [
    "# list all tables, since we only have 1, use the first in the list at index 0\n",
    "my_table = soup.find_all('table')[0]\n",
    "# or just use: my_table = soup.find('table')\n",
    "\n",
    "# loop the rows and keep the row number\n",
    "row_num = 0\n",
    "for row in my_table.find_all('tr'):\n",
    "    print(\"Row: \"+str(row_num))\n",
    "    row_num = row_num+1\n",
    "\n",
    "    #loop the cells in the row\n",
    "    for cell in row.find_all('td'):\n",
    "        print(\"whole html:\", str(cell)+\" \\tJust content: \"+cell.text)\n",
    "        \n",
    "# if you'd like, try to change this code to use .findChildren( ) rather than .find_all('tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red'>Why does it print all the row numers after each children tags. Need to check</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Whole html: <td>100</td> \tJUst the text: 100\n",
      "Whole html: <td>200</td> \tJUst the text: 200\n",
      "Whole html: <td>300</td> \tJUst the text: 300\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Whole html: <td>400</td> \tJUst the text: 400\n",
      "Whole html: <td>500</td> \tJUst the text: 500\n",
      "Whole html: <td>600</td> \tJUst the text: 600\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Whole html: <td>700</td> \tJUst the text: 700\n",
      "Whole html: <td>800</td> \tJUst the text: 800\n",
      "Whole html: <td>900</td> \tJUst the text: 900\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "new_table = soup.find_all('table')[0]\n",
    "#first_child=new_table.findChildren()\n",
    "for row_num, each_elements in enumerate(new_table.findChildren()):\n",
    "    print(row_num)\n",
    "    print() #print each children\n",
    "    #second_child=each_elements.findChildren()\n",
    "    for each_cell in each_elements.findChildren():\n",
    "        print('Whole html:', each_cell, '\\tJUst the text:', each_cell.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minitask: Now attempt to scrape something from a real online website:\n",
    "\n",
    "Use the above code to make a list of all the degrees available in business school of University of Edinburgh. \n",
    "\n",
    "1. You will need to get the source of the page the list is on and feed it into the breautiful soup (see code above). (use this url instead of our demo website file://..... use this:  https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12)\n",
    "2. get the html component that holds all the degrees. Use developer tools to identify what type of component it is (hint: ul stamds for \"unordered list\"). Does this component have a class or an id? How would you get a component when you know it's id? (hint: proxy_degreeList )\n",
    "3. What type of a tag are the actual names of degrees in? (div, a, p, or something else) hint: what tag surround the name of the course?\n",
    "4. Grab children of that type from the component with all names and in a loop, extract only the text of each of them. And print them.\n",
    "\n",
    "\n",
    "I am posting the solution lower down, but do try to solve it by yourself first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy-paste relevant parts of the code from above to start:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only uncover the solutions once you tried to complete the task:\n",
    "    \n",
    "    \n",
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE HINT 1.</summary>\n",
    "\n",
    "1. You will need to get the source of the page the list is on and feed it into the breautiful soup (see code above). (use this url instead of our demo website file://..... use this:  https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12)\n",
    "\n",
    "```\n",
    "file_url = \"https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12\"\n",
    "website_source_code = urlopen(file_url)\n",
    "soup_degrees_website = BeautifulSoup(website_source_code, 'html.parser')\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE HINT 2.</summary>\n",
    "\n",
    " 2. get the html component that holds all the degrees.  Use developer tools to identify what type of component it is (hint: ul stamds for \"unordered list\").  Does this component have a class or an id? How would you get a component when you know it's id?  (hint: proxy_degreeList )\n",
    "```\n",
    "degrees = soup_degrees_website.find(id='proxy_degreeList')\n",
    " ```   \n",
    "</details>\n",
    "\n",
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE HINT 3.</summary>\n",
    "\n",
    " 3. What type of a tag are the actual names of degrees in? (div, a, p, or something else) hint: what tag surround the name of the course?\n",
    "``` \n",
    "for list_item in degrees.findChildren(\"a\"):\n",
    "  ```  \n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE HINT 4.</summary>\n",
    "\n",
    "4. Grab children of that type from the component with all names and in a loop, extract only the text of each of them. And print them.\n",
    "```\n",
    "    print(\"Degree Name:\", list_item.text)\n",
    "    ```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12\"\n",
    "website_source_code = urlopen(file_url)\n",
    "soup_degrees_website = BeautifulSoup(website_source_code, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Name: Business and Economics (MA) NL11\n",
      "Degree Name: Business and Geography (MA) NL17\n",
      "Degree Name: Business and Law (MA) NM11\n",
      "Degree Name: Business Management (MA) N100\n",
      "Degree Name: Business with Decision Analytics (MA) NN12\n",
      "Degree Name: Business with Enterprise and Innovation (MA) N1N2\n",
      "Degree Name: Business with Human Resource Management (MA) N1N6\n",
      "Degree Name: Business with Marketing (MA) N1N5\n",
      "Degree Name: Business with Strategic Economics (MA) N1L1\n",
      "Degree Name: Finance and Business (MA) NN13\n",
      "Degree Name: International Business (MA) N120\n",
      "Degree Name: International Business with Arabic (MA) N1T6\n",
      "Degree Name: International Business with Chinese (MA) N1T1\n",
      "Degree Name: International Business with French (MA) N1R1\n",
      "Degree Name: International Business with German (MA) N1R2\n",
      "Degree Name: International Business with Italian (MA) N1R3\n",
      "Degree Name: International Business with Japanese (MA) N1T2\n",
      "Degree Name: International Business with Russian (MA) N1R7\n",
      "Degree Name: International Business with Spanish (MA) N1R4\n"
     ]
    }
   ],
   "source": [
    "degrees = soup_degrees_website.find(id='proxy_degreeList')\n",
    "for list_item in degrees.findChildren(\"a\"):\n",
    "     print(\"Degree Name:\", list_item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Name: Business and Economics (MA) NL11\n",
      "\n",
      "Degree Name: Business and Geography (MA) NL17\n",
      "\n",
      "Degree Name: Business and Law (MA) NM11\n",
      "\n",
      "Degree Name: Business Management (MA) N100\n",
      "\n",
      "Degree Name: Business with Decision Analytics (MA) NN12\n",
      "\n",
      "Degree Name: Business with Enterprise and Innovation (MA) N1N2\n",
      "\n",
      "Degree Name: Business with Human Resource Management (MA) N1N6\n",
      "\n",
      "Degree Name: Business with Marketing (MA) N1N5\n",
      "\n",
      "Degree Name: Business with Strategic Economics (MA) N1L1\n",
      "\n",
      "Degree Name: Finance and Business (MA) NN13\n",
      "\n",
      "Degree Name: International Business (MA) N120\n",
      "\n",
      "Degree Name: International Business with Arabic (MA) N1T6\n",
      "\n",
      "Degree Name: International Business with Chinese (MA) N1T1\n",
      "\n",
      "Degree Name: International Business with French (MA) N1R1\n",
      "\n",
      "Degree Name: International Business with German (MA) N1R2\n",
      "\n",
      "Degree Name: International Business with Italian (MA) N1R3\n",
      "\n",
      "Degree Name: International Business with Japanese (MA) N1T2\n",
      "\n",
      "Degree Name: International Business with Russian (MA) N1R7\n",
      "\n",
      "Degree Name: International Business with Spanish (MA) N1R4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using li gives a space after each degree name\n",
    "all_degrees = soup_degrees_website.find(id='proxy_degreeList')\n",
    "for new_list_item in all_degrees.findChildren(\"li\"):\n",
    "     print(\"Degree Name:\", new_list_item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New changes added should be committed on git otherwise will be lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
